{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport tensorflow as tf\\n\\n# Construct a basic model.\\nroot = tf.train.Checkpoint()\\nroot.v1 = tf.Variable(3.)\\nroot.v2 = tf.Variable(2.)\\nroot.f = tf.function(lambda x: root.v1 * root.v2 * x)\\n\\n# Save the model.\\nexport_dir = \"/tmp/test_saved_model\"\\ninput_data = tf.constant(1., shape=[1, 1])\\nto_save = root.f.get_concrete_function(input_data)\\ntf.saved_model.save(root, export_dir, to_save)\\n\\n# Convert the model.\\nconverter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\\ntflite_model = converter.convert()\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "# Construct a basic model.\n",
    "root = tf.train.Checkpoint()\n",
    "root.v1 = tf.Variable(3.)\n",
    "root.v2 = tf.Variable(2.)\n",
    "root.f = tf.function(lambda x: root.v1 * root.v2 * x)\n",
    "\n",
    "# Save the model.\n",
    "export_dir = \"/tmp/test_saved_model\"\n",
    "input_data = tf.constant(1., shape=[1, 1])\n",
    "to_save = root.f.get_concrete_function(input_data)\n",
    "tf.saved_model.save(root, export_dir, to_save)\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "tflite_model = converter.convert()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "import os\n",
    "from tensorflow.summary import FileWriter\n",
    "import numpy as np\n",
    "import glob\n",
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-7759025917dd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-36-7759025917dd>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def output_tb:\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def output_tb:\n",
    "    sess = tf.Session()\n",
    "    tf.train.import_meta_graph(\"..\\\\ExpResults\\\\256x64\\\\model_512x32_lr_0_008_20200110.meta\")\n",
    "    FileWriter(\"__tb\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2pb(meta_path,dir_name):\n",
    "#     meta_path = 'model.ckpt-22480.meta' # Your .meta file\n",
    "#     output_node_names = ['output:0']    # Output nodes\n",
    "    \n",
    "#     print(output_node_names)\n",
    "    init=tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        # Restore the graph\n",
    "        saver = tf.train.import_meta_graph(meta_path)\n",
    "\n",
    "        # Load weights\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(dir_name))\n",
    "        \n",
    "        sess.run(init)\n",
    "#         vars_train = tf.trainable_variables() \n",
    "#         output_node_names = [var.name.split(\":\")[0] for var in vars_train]\n",
    "#         output_node_names = [n.name for n in tf.get_default_graph().as_graph_def().node]\n",
    "#         print(output_node_names)\n",
    "        graph_def = tf.get_default_graph().as_graph_def()\n",
    "        \n",
    "#         print(graph_def)\n",
    "        # Freeze the graph\n",
    "        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            graph_def,\n",
    "            ['gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax'])\n",
    "\n",
    "        # Save the frozen graph\n",
    "        with open('output_graph.pb', 'wb') as f:\n",
    "          f.write(frozen_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2tflite(saved_model_dir):\n",
    "#     saved_model_dir = \"../lite_models\"\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"512x32_0008.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we import the graph_def into a new Graph and return it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exist\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"../ExpResults/512x32_lr_0008/model_512x32_lr_0_008_20200110.meta\"):\n",
    "    print(\"file exist\")\n",
    "else:\n",
    "    print(\"file does not exist\")\n",
    "# convert2pb(\"..\\\\ExpResults\\\\256x64\\\\model_512x32_lr_0_008_20200110.meta\",\"..\\\\ExpResults\\\\256x64\")\n",
    "# tmp_graph = load_graph(\"..\\\\ExpResults\\\\256x64\\\\model_512x32_lr_0_008_20200110.meta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_input_output_arrays(pb_file):\n",
    "    gf = tf.GraphDef()   \n",
    "    in_pb_file = open(pb_file,'rb')\n",
    "    gf.ParseFromString(in_pb_file.read())\n",
    "\n",
    "    with open('parameters.txt', 'a+') as the_file:\n",
    "        for n in gf.node:\n",
    "            the_file.write(n.name+'\\n')\n",
    "\n",
    "    file = open('parameters.txt','r')\n",
    "    data = file.readlines()\n",
    "    print(\"output name = \")\n",
    "    print(data[len(data)-1])\n",
    "\n",
    "    print(\"Input name = \")\n",
    "    file.seek ( 0 )\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_input_output_arrays(\"../tensorflow_pb_files/512x32.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tflite(tflite_file=None):\n",
    "\n",
    "\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"../tensorflow_pb_files/512x32.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    print(input_details)\n",
    "    print(output_details)\n",
    "\n",
    "#     # Test model on random input data.\n",
    "#     input_shape = input_details[0]['shape']\n",
    "#     input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "#     interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "#     interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    input_data = interpreter.get_tensor(input_details[0]['index'])\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(input_data)\n",
    "    print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_tflite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite2CArray(pbfile):\n",
    "    basic_model_size = os.path.getsize(pbfile)\n",
    "    print(\"Basic model is %d bytes\" % basic_model_size)\n",
    "    quantized_model_size = os.path.getsize(pbfile)\n",
    "    print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
    "    difference = basic_model_size - quantized_model_size\n",
    "    print(\"Difference is %d bytes\" % difference)\n",
    "    #****************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic model is 41112 bytes\n",
      "Quantized model is 41112 bytes\n",
      "Difference is 0 bytes\n"
     ]
    }
   ],
   "source": [
    "tflite2CArray(\"../tensorflow_pb_files/512x32.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeightFromTFLite(tflite_file):\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_file)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "    # get details for each layer\n",
    "    all_layers_details = interpreter.get_tensor_details() \n",
    "    \n",
    "#     for layer in all_layers_details:\n",
    "#         print(\"layer name={}\".format(layer['name']))\n",
    "#         print(\"layer shape={}\".format(layer['shape']))\n",
    "#         data=interpreter.get_tensor(layer['index'])\n",
    "#         print(\"data is: \\n{}\".format(data))\n",
    "    \n",
    "#     for layer in all_layers_details:\n",
    "#         if layer['name'] == \"Variable_6/transpose\" \\\n",
    "#         or layer['name'] == \"Variable_7/transpose\" \\\n",
    "#         or layer['name']==\"Variable_8/transpose\" \\\n",
    "#         or layer['name']==\"Relu_2\" \\\n",
    "#         or layer['name']==\"Relu_3\" \\\n",
    "#         or layer['name']==\"gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax\":\n",
    "#             print(\"layer name={}\".format(layer['name']))\n",
    "#             print(\"layer shape={}\".format(layer['shape']))\n",
    "#             data=interpreter.get_tensor(layer['index'])\n",
    "#             print(\"data is: \\n{}\".format(data))\n",
    "     \n",
    "    weight1 = []\n",
    "    weight2 = []\n",
    "    weight3 = []\n",
    "    bias1 = []\n",
    "    bias2= []\n",
    "    bias3 = []\n",
    "    for layer in all_layers_details:\n",
    "        if layer['name']==\"Relu_2\":\n",
    "            bias1 = interpreter.get_tensor(layer['index'])\n",
    "        \n",
    "        if layer['name']==\"Relu_3\":\n",
    "            bias2 = interpreter.get_tensor(layer['index'])\n",
    "            \n",
    "        if layer['name']==\"gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax\":\n",
    "            bias3 = interpreter.get_tensor(layer['index'])\n",
    "            \n",
    "        if layer['name']==\"Variable_6/transpose\":\n",
    "            w1_tranpose = np.array(interpreter.get_tensor(layer['index']))\n",
    "            weight1 = w1_tranpose.T\n",
    "            \n",
    "        if layer['name']==\"Variable_7/transpose\":\n",
    "            w2_tranpose = np.array(interpreter.get_tensor(layer['index']))\n",
    "            weight2 = w2_tranpose.T\n",
    "            \n",
    "        if layer['name']==\"Variable_8/transpose\":\n",
    "            w3_tranpose = np.array(interpreter.get_tensor(layer['index']))\n",
    "            weight3 = w3_tranpose.T\n",
    "            \n",
    "    print(\"w1.shape = {},\\n w2.shape = {},\\n w3.shape = {}\\n\".format(weight1.shape, weight2.shape, weight3.shape))\n",
    "    \n",
    "    spio.savemat(\"testsavemat.mat\",\\\n",
    "                 {'w1': weight1,'w2':weight2,'w3':weight3,\\\n",
    "                 'b1':bias1,'b2':bias2,'b3':bias3})\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "#     f = h5py.File(\"512x32_weights.hdf5\", \"w\")   \n",
    "\n",
    "#     for layer in all_layers_details:\n",
    "#          # to create a group in an hdf5 file\n",
    "#          grp = f.create_group(str(layer['index']))\n",
    "\n",
    "#          # to store layer's metadata in group's metadata\n",
    "#          grp.attrs[\"name\"] = layer['name']\n",
    "#          grp.attrs[\"shape\"] = layer['shape']\n",
    "#          # grp.attrs[\"dtype\"] = all_layers_details[i]['dtype']\n",
    "#          grp.attrs[\"quantization\"] = layer['quantization']\n",
    "\n",
    "#          # to store the weights in a dataset\n",
    "#          grp.create_dataset(\"weights\", data=interpreter.get_tensor(layer['index']))\n",
    "\n",
    "\n",
    "#      f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1.shape = (40, 512),\n",
      " w2.shape = (512, 32),\n",
      " w3.shape = (32, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "getWeightFromTFLite(\"../tensorflow_pb_files/512x32.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport tensorflow as tf\\n\\n# Construct a basic model.\\nroot = tf.train.Checkpoint()\\nroot.v1 = tf.Variable(3.)\\nroot.v2 = tf.Variable(2.)\\nroot.f = tf.function(lambda x: root.v1 * root.v2 * x)\\n\\n# Save the model.\\nexport_dir = \"/tmp/test_saved_model\"\\ninput_data = tf.constant(1., shape=[1, 1])\\nto_save = root.f.get_concrete_function(input_data)\\ntf.saved_model.save(root, export_dir, to_save)\\n\\n# Convert the model.\\nconverter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\\ntflite_model = converter.convert()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "# Construct a basic model.\n",
    "root = tf.train.Checkpoint()\n",
    "root.v1 = tf.Variable(3.)\n",
    "root.v2 = tf.Variable(2.)\n",
    "root.f = tf.function(lambda x: root.v1 * root.v2 * x)\n",
    "\n",
    "# Save the model.\n",
    "export_dir = \"/tmp/test_saved_model\"\n",
    "input_data = tf.constant(1., shape=[1, 1])\n",
    "to_save = root.f.get_concrete_function(input_data)\n",
    "tf.saved_model.save(root, export_dir, to_save)\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "tflite_model = converter.convert()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "import os\n",
    "from tensorflow.summary import FileWriter\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_tb():\n",
    "    sess = tf.Session()\n",
    "    tf.train.import_meta_graph(\"..\\\\ExpResults\\\\256x64\\\\model_512x32_lr_0_008_20200110.meta\")\n",
    "    FileWriter(\"__tb\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2pb_original(meta_path,dir_name):\n",
    "#     meta_path = 'model.ckpt-22480.meta' # Your .meta file\n",
    "#     output_node_names = ['output:0']    # Output nodes\n",
    "    \n",
    "#     print(output_node_names)\n",
    "    init=tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        # Restore the graph\n",
    "        saver = tf.train.import_meta_graph(meta_path)\n",
    "\n",
    "        # Load weights\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(dir_name))\n",
    "        \n",
    "#         vars_train = tf.trainable_variables() \n",
    "#         output_node_names = [var.name.split(\":\")[0] for var in vars_train]\n",
    "#         output_node_names = [n.name for n in tf.get_default_graph().as_graph_def().node]\n",
    "#         print(output_node_names)\n",
    "        graph_def = tf.get_default_graph().as_graph_def()\n",
    "        \n",
    "#         print(graph_def)\n",
    "        # Freeze the graph\n",
    "        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            graph_def,\n",
    "            ['gradients_2/softmax_cross_entropy_with_logits_2_grad/LogSoftmax'])\n",
    "\n",
    "        # Save the frozen graph\n",
    "        with open('output_graph128x64.pb', 'wb') as f:\n",
    "          f.write(frozen_graph_def.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ..\\ExpResults\\256x64\\model_128x64_lr_0_008_20200110\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "convert2pb_original(\"..\\\\ExpResults\\\\256x64\\\\model_128x64_lr_0_008_20200110.meta\",\"..\\\\ExpResults\\\\256x64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2pb(full_meta_file_name,checkpoint_dir,export_pb_name,output_node_name):\n",
    "    init=tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        # Restore the graph\n",
    "        saver = tf.train.import_meta_graph(full_meta_file_name)\n",
    "        # Load weights\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(checkpoint_dir))\n",
    "        graph_def = tf.get_default_graph().as_graph_def()\n",
    "        # Freeze the graph\n",
    "        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            graph_def,\n",
    "            [\"gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax\"])\n",
    "        #'gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax'\n",
    "        # Save the frozen graph\n",
    "        with open(export_pb_name, 'wb') as f:\n",
    "            f.write(frozen_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\models\\model_128x64_lr_0_008_20200110\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable_7\n\t [[{{node _retval_Variable_7_0_3}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mD:\\SoftwareIns\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareIns\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareIns\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_7\n\t [[{{node _retval_Variable_7_0_3}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-88178472bd9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconvert2pb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models\\\\model_128x64_lr_0_008_20200110.meta\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\".\\\\models\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"export_dir\\\\output.pb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-963d8b1ba2e8>\u001b[0m in \u001b[0;36mconvert2pb\u001b[1;34m(full_meta_file_name, checkpoint_dir, export_pb_name, output_node_name)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             [\"gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax\"])\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;31m#'gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Save the frozen graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareIns\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareIns\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\graph_util_impl.py\u001b[0m in \u001b[0;36mconvert_variables_to_constants\u001b[1;34m(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)\u001b[0m\n\u001b[0;32m    328\u001b[0m   \u001b[1;31m# Gets map of variables and the associated data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m     \u001b[0mreturned_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[0mreturned_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareIns\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareIns\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareIns\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\SoftwareIns\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_7\n\t [[{{node _retval_Variable_7_0_3}}]]"
     ]
    }
   ],
   "source": [
    "convert2pb(\"models\\\\model_128x64_lr_0_008_20200110.meta\",\".\\\\models\",\"export_dir\\\\output.pb\",'gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2tflite(saved_model_dir):\n",
    "#     saved_model_dir = \"../lite_models\"\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "    tflite_model = converter.convert()\n",
    "    open(\"512x32_0008.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we import the graph_def into a new Graph and return it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exist\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"../ExpResults/512x32_lr_0008/model_512x32_lr_0_008_20200110.meta\"):\n",
    "    print(\"file exist\")\n",
    "else:\n",
    "    print(\"file does not exist\")\n",
    "# convert2pb(\"..\\\\ExpResults\\\\256x64\\\\model_512x32_lr_0_008_20200110.meta\",\"..\\\\ExpResults\\\\256x64\")\n",
    "# tmp_graph = load_graph(\"..\\\\ExpResults\\\\256x64\\\\model_512x32_lr_0_008_20200110.meta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_input_output_arrays(pb_file):\n",
    "    gf = tf.GraphDef()   \n",
    "    in_pb_file = open(pb_file,'rb')\n",
    "    gf.ParseFromString(in_pb_file.read())\n",
    "\n",
    "    with open('parameters.txt', 'a+') as the_file:\n",
    "        for n in gf.node:\n",
    "            the_file.write(n.name+'\\n')\n",
    "\n",
    "    file = open('parameters.txt','r')\n",
    "    data = file.readlines()\n",
    "    print(\"output name = \")\n",
    "    print(data[len(data)-1])\n",
    "\n",
    "    print(\"Input name = \")\n",
    "    file.seek ( 0 )\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output name = \n",
      "gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax\n",
      "\n",
      "Input name = \n",
      "Placeholder_2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_input_output_arrays(\"../tensorflow_pb_files/512x32.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tflite(tflite_file=None):\n",
    "\n",
    "\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"../tensorflow_pb_files/512x32.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    print(input_details)\n",
    "    print(output_details)\n",
    "\n",
    "#     # Test model on random input data.\n",
    "#     input_shape = input_details[0]['shape']\n",
    "#     input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "#     interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "#     interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    input_data = interpreter.get_tensor(input_details[0]['index'])\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(input_data)\n",
    "    print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Placeholder_2', 'index': 4, 'shape': array([ 1, 40]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.007874015718698502, 128)}]\n",
      "[{'name': 'gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax', 'index': 10, 'shape': array([1, 2]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0625, 255)}]\n",
      "[[108 108  32  78  97  78  32 118  97 108 117 101 115  32 117 115 105 110\n",
      "  103  32 105 110 116 101 114 112 111 108  97 116 105 111 110  46  10 114\n",
      "  101 105 110 100]]\n",
      "[[120  97]]\n"
     ]
    }
   ],
   "source": [
    "load_tflite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite2CArray(pbfile):\n",
    "    basic_model_size = os.path.getsize(pbfile)\n",
    "    print(\"Basic model is %d bytes\" % basic_model_size)\n",
    "    quantized_model_size = os.path.getsize(pbfile)\n",
    "    print(\"Quantized model is %d bytes\" % quantized_model_size)\n",
    "    difference = basic_model_size - quantized_model_size\n",
    "    print(\"Difference is %d bytes\" % difference)\n",
    "    #****************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic model is 41112 bytes\n",
      "Quantized model is 41112 bytes\n",
      "Difference is 0 bytes\n"
     ]
    }
   ],
   "source": [
    "tflite2CArray(\"../tensorflow_pb_files/512x32.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeightFromTFLite(tflite_file):\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_file)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "    # get details for each layer\n",
    "    all_layers_details = interpreter.get_tensor_details() \n",
    "\n",
    "\n",
    "#     f = h5py.File(\"512x32_weights.hdf5\", \"w\")   \n",
    "\n",
    "#     for layer in all_layers_details:\n",
    "#          # to create a group in an hdf5 file\n",
    "#          grp = f.create_group(str(layer['index']))\n",
    "\n",
    "#          # to store layer's metadata in group's metadata\n",
    "#          grp.attrs[\"name\"] = layer['name']\n",
    "#          grp.attrs[\"shape\"] = layer['shape']\n",
    "#          # grp.attrs[\"dtype\"] = all_layers_details[i]['dtype']\n",
    "#          grp.attrs[\"quantization\"] = layer['quantization']\n",
    "\n",
    "#          # to store the weights in a dataset\n",
    "#          grp.create_dataset(\"weights\", data=interpreter.get_tensor(layer['index']))\n",
    "\n",
    "\n",
    "#      f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

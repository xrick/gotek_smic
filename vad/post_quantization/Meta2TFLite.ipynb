{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import glob\n",
    "import scipy.io as spio\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2PB_tf_compat():\n",
    "    trained_checkpoint_prefix = \"model_512x32_lr_0_008_20200110\"\n",
    "    saved_model_path = '512x32_to_tflite_test2'\n",
    "    export_dir = \"export_dir\"\n",
    "\n",
    "    print(export_dir)\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with tf.compat.v1.Session(graph=graph) as sess:\n",
    "        # Restore from checkpoint\n",
    "        loader = tf.compat.v1.train.import_meta_graph(saved_model_path + \"/\"+ trained_checkpoint_prefix + '.meta')\n",
    "        loader.restore(sess, saved_model_path)\n",
    "\n",
    "        # Export checkpoint to SavedModel\n",
    "        builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "        builder.add_meta_graph_and_variables(sess,\n",
    "                                             [tf.saved_model.TRAINING, tf.saved_model.SERVING],\n",
    "                                             strip_default_attrs=True)\n",
    "        builder.save()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2PB_Ori(meta_path, dir_name, output_node_name, output_pb_name):\n",
    "    init=tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        # Restore the graph\n",
    "        saver = tf.train.import_meta_graph(meta_path)\n",
    "\n",
    "        # Load weights\n",
    "        saver.restore(sess,tf.train.latest_checkpoint(dir_name))\n",
    "        \n",
    "        graph_def = tf.get_default_graph().as_graph_def()\n",
    "        \n",
    "        # Freeze the graph\n",
    "        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            graph_def,\n",
    "            [output_node_name])\n",
    "        #'gradients_2/softmax_cross_entropy_with_logits_2_grad/LogSoftmax'\n",
    "        # Save the frozen graph\n",
    "        with open(dir_name+\"/\"+output_pb_name, 'wb') as f:\n",
    "          f.write(frozen_graph_def.SerializeToString())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert2PB_Ori(\"../TrainedModels/512x32_20200116_23_23_34/model_512x32_20200116_23_23_34.meta\", \\\n",
    "#                \"../TrainedModels/512x32_20200116_23_23_34\",\"gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax\", \\\n",
    "#               \"output_512x32.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../TrainedModels/256x64_20200117_04_04_38\\model_256x64_20200117_04_04_38\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "#gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax\n",
    "Convert2PB_Ori(\"../TrainedModels/256x64_20200117_04_04_38/model_256x64_20200117_04_04_38.meta\", \\\n",
    "               \"../TrainedModels/256x64_20200117_04_04_38\",\n",
    "               \"gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax\", \\\n",
    "               \"output_256x64_conversion2.pb\")\n",
    "\n",
    "#\"gradients_1/softmax_cross_entropy_with_logits_1_grad/LogSoftmax\" (256x64)\n",
    "#\"gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax\" (512x32) input:Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tflite_convert \\\n",
    "  --output_file=/tmp/foo.tflite \\\n",
    "  --graph_def_file=/tmp/some_quantized_graph.pb \\\n",
    "  --inference_type=QUANTIZED_UINT8 \\\n",
    "  --input_arrays=input \\\n",
    "  --output_arrays=MobilenetV1/Predictions/Reshape_1 \\\n",
    "  --mean_values=128 \\\n",
    "  --std_dev_values=127\n",
    "  --default_ranges_min=0 \\\n",
    "  --default_ranges_max=6 \\\n",
    "\"\"\"\n",
    "def Convert2PB_with_TFLite_Converter(pb_name, \\\n",
    "                                     output_lite_name, \\\n",
    "                                     input_node_array, \\\n",
    "                                     output_node_array, \\\n",
    "                                     meanValue,         \\\n",
    "                                     stddevValue,\\\n",
    "                                     maxvalue,\n",
    "                                     minvalue):\n",
    "    seperator = ' '\n",
    "    argvlist = [\n",
    "          \"tflite_convert \"\n",
    "          \"--output_file={}\".format(output_lite_name),\n",
    "          \"--graph_def_file={}\".format(pb_name),\n",
    "          \"--input_format=TENSORFLOW_GRAPHDEF\", \\\n",
    "          \"--output_format=TFLITE\", \\\n",
    "          \"--inference_type=QUANTIZED_UINT8\",\n",
    "          \"--input_type=QUANTIZED_UINT8\",\n",
    "#           \"--input_type=QUANTIZED_UINT8\",\n",
    "          \"--input_arrays={}\".format(input_node_array),\n",
    "          \"--output_arrays={}\".format(output_node_array),\n",
    "          \"--mean_values={}\".format(meanValue),\n",
    "          \"--std_dev_values={}\".format(stddevValue),\n",
    "          \"--default_ranges_max={}\".format(maxvalue),\n",
    "          \"--default_ranges_min={}\".format(minvalue)\n",
    "          \n",
    "    ]\n",
    "#     seperator.join(\"tflite_convert\")\n",
    "    run_command = seperator.join(argvlist)\n",
    "    print(run_command)\n",
    "    print(\"\\n\")\n",
    "    subprocess.call(run_command)\n",
    "#     exec(\"tflite_convert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tflite_convert --output_file=../TrainedModels/512x32_20200116_23_23_34/tflite_512x32_gen3.tflite --graph_def_file=../TrainedModels/512x32_20200116_23_23_34/output_512x32.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --inference_type=QUANTIZED_UINT8 --input_type=QUANTIZED_UINT8 --input_arrays=Placeholder --output_arrays=gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax --mean_values=128 --std_dev_values=127 --default_ranges_max=255 --default_ranges_min=0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_max = str(sys.maxsize)\n",
    "_min = 0 #-sys.maxsize -1\n",
    "Convert2PB_with_TFLite_Converter(\"../TrainedModels/512x32_20200116_23_23_34/output_512x32.pb\" , \\\n",
    "                                 \"../TrainedModels/512x32_20200116_23_23_34/tflite_512x32_gen3.tflite\",\\\n",
    "                                 \"Placeholder\",\\\n",
    "                                 \"gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax\",\\\n",
    "                                 \"128\",\\\n",
    "                                 \"127\",\n",
    "                                 255,\n",
    "                                 0\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short way for output tflite???\n",
    "def Convert2TFLite(saved_model_dir,tflitefile):\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "    tflite_model = converter.convert()\n",
    "    open(saved_model_dir+\"/\"+tflitefile, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_tb_for_tensorboard():\n",
    "    sess = tf.Session()\n",
    "    tf.train.import_meta_graph(\"..\\\\ExpResults\\\\256x64\\\\model_512x32_lr_0_008_20200110.meta\")\n",
    "    FileWriter(\"__tb\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genWeightFromTFLite(tflite_file, ouput_mat_file):\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_file)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "    # get details for each layer\n",
    "    all_layers_details = interpreter.get_tensor_details() \n",
    "    \n",
    "\n",
    "#     for layer in all_layers_details:\n",
    "#         print(\"layer name={}\".format(layer['name']))\n",
    "#         print(\"layer shape={}\".format(layer['shape']))\n",
    "#         data=interpreter.get_tensor(layer['index'])\n",
    "#         print(\"data is: \\n{}\".format(data))\n",
    "    \n",
    "\n",
    "    weight1 = []\n",
    "    weight2 = []\n",
    "    weight3 = []\n",
    "    bias1 = []\n",
    "    bias2= []\n",
    "    bias3 = []\n",
    "    for layer in all_layers_details:\n",
    "        if layer['name']==\"MatMul_1_bias\":\n",
    "            bias1 = interpreter.get_tensor(layer['index'])\n",
    "\n",
    "        if layer['name']==\"MatMul_2_bias\":\n",
    "            bias2 = interpreter.get_tensor(layer['index'])\n",
    "\n",
    "        if layer['name']==\"MatMul_bias\":\n",
    "             bias3 = interpreter.get_tensor(layer['index'])\n",
    "\n",
    "        if layer['name']==\"Variable/transpose\":\n",
    "            w1_tranpose = np.array(interpreter.get_tensor(layer['index']))\n",
    "            weight1 = w1_tranpose.T\n",
    "\n",
    "        if layer['name']==\"Variable_1/transpose\":\n",
    "            w2_tranpose = np.array(interpreter.get_tensor(layer['index']))\n",
    "            weight2 = w2_tranpose.T\n",
    "\n",
    "        if layer['name']==\"Variable_2/transpose\":\n",
    "            w3_tranpose = np.array(interpreter.get_tensor(layer['index']))\n",
    "            weight3 = w3_tranpose.T\n",
    "\n",
    "    print(\"w1.shape = {},\\n w2.shape = {},\\n w3.shape = {}\\n\".format(weight1.shape, weight2.shape, weight3.shape))\n",
    "\n",
    "    spio.savemat(ouput_mat_file,\\\n",
    "                {'w1': weight1,'w2':weight2,'w3':weight3,\\\n",
    "                'b1':bias1,'b2':bias2,'b3':bias3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1.shape = (40, 512),\n",
      " w2.shape = (512, 32),\n",
      " w3.shape = (32, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genWeightFromTFLite(\"../TrainedModels/512x32_20200116_23_23_34/tflite_512x32_gen3.tflite\",\n",
    "                    \"../TrainedModels/512x32_20200116_23_23_34/512x32_gen3.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

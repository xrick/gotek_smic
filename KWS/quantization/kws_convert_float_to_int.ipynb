{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wave\n",
    "import os\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "# from os import listdir\n",
    "# from os.path import isfile, isdir, join\n",
    "import wave\n",
    "import struct\n",
    "from tqdm import tqdm\n",
    "# import tensorflow as tf\n",
    "import scipy.io as spio\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_int32_value = 2147483647\n",
    "converted_training_mat_file = \"../data/quantized_kws_weights/quant_kw_20200620.mat\"\n",
    "originat_weight_mat = \"../data/kws_weights/kw_dnn128_20200619_18_47_16.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S(bits):\n",
    "    return 2.0 ** (bits - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conversion():\n",
    "    testary = np.array([[0.546846464, 0.96796461, 0.7496664],[0.48649646,0.32466841,0.5346434]])\n",
    "    res_ary = performConvertion(testary, 1000000, 'uint32')\n",
    "    print(res_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_weights(weightFile):\n",
    "#     dict_data = spio.loadmat(weightFile)\n",
    "#     w1 = dict_data[\"w1\"]\n",
    "#     w2 = dict_data[\"w2\"]\n",
    "#     w3 = dict_data[\"w3\"]\n",
    "#     b1 = dict_data[\"b1\"]\n",
    "#     b2 = dict_data[\"b2\"]\n",
    "#     b3 = dict_data[\"b3\"]\n",
    "#     return w1, w2, w3, b1, b2, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for load training data\n",
    "def load_training_data(fileName):\n",
    "    ret_mat = spio.loadmat(fileName)[\"x_data\"]\n",
    "    return ret_mat\n",
    "\n",
    "def performConvertion(src_array, scalar_multiplier, dtypeStr):\n",
    "    #ret_clip = (audio_array[0:mat_len]*max_value).astype(dtype='double')\n",
    "    processed_array = (src_array*scalar_multiplier).astype(dtypeStr)\n",
    "    return processed_array\n",
    "\n",
    "def performAdvnacedConvertion(src_array,bits,dtypeStr):\n",
    "    scale = S(bits)\n",
    "    w1,w2,w3,b1,b2,b3 = load_weights(src_array)\n",
    "    quant_w1 = quant_weight(w1,8)\n",
    "    print(quant_w1)\n",
    "#     return processedWeight\n",
    "\n",
    "def load_weights(weightFile):\n",
    "    dict_data = spio.loadmat(weightFile)\n",
    "    w1 = dict_data[\"w1\"]\n",
    "    w2 = dict_data[\"w2\"]\n",
    "    w3 = dict_data[\"w3\"]\n",
    "    w4 = dict_data[\"w4\"]\n",
    "    b1 = dict_data[\"b1\"]\n",
    "    b2 = dict_data[\"b2\"]\n",
    "    b3 = dict_data[\"b3\"]\n",
    "    b4 = dict_data[\"b4\"]\n",
    "    return w1, w2, w3, w4, b1, b2, b3, b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant_weight(ori_weight, bits, typeStr):\n",
    "    min_wt = np.amin(ori_weight)\n",
    "    max_wt = np.amax(ori_weight)\n",
    "    # calculat the bits necessary for representing the range\n",
    "    repr_bits = int(np.ceil(np.log2(max(abs(min_wt),abs(max_wt)))))\n",
    "    frac_bits = bits-repr_bits-1\n",
    "    quant_weight = np.round(ori_weight*(2**frac_bits)).astype(typeStr)\n",
    "    # we need to return the frac_bits for the reason that when we do the inference\n",
    "    # we need to scale the quantized weights to their original range by\n",
    "    # weight = quant_weight * 2^frac_bits\n",
    "    return quant_weight, frac_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performConversion(srcWeightFile, bits,typeStr,des_file):\n",
    "    w1,w2,w3,w4,b1,b2,b3,b4 = load_weights(srcWeightFile)\n",
    "    quant_w1, frac_bits1 = quant_weight(w1,bits,typeStr)\n",
    "    quant_w2, frac_bits2 = quant_weight(w2,bits,typeStr)\n",
    "    quant_w3, frac_bits3 = quant_weight(w3,bits,typeStr)\n",
    "    quant_w4, frac_bits4 = quant_weight(w4,bits,typeStr)\n",
    "    \n",
    "    quant_b1, frac_bits5 = quant_weight(b1,bits,typeStr)\n",
    "    quant_b2, frac_bits6 = quant_weight(b2,bits,typeStr)\n",
    "    quant_b3, frac_bits7 = quant_weight(b3,bits,typeStr)\n",
    "    quant_b4, frac_bits8 = quant_weight(b4,bits,typeStr)\n",
    "    print(\"\\nquant_w2 is\\n{}\".format(quant_w2))\n",
    "    print(\"\\nquant_scale for w1 is\\n{}\".format(frac_bits1))\n",
    "    print(\"\\nquant_scale for w2 is\\n{}\".format(frac_bits2))\n",
    "    print(\"\\nquant_scale for w3 is\\n{}\".format(frac_bits3))\n",
    "    print(\"\\nquant_scale for w4 is\\n{}\".format(frac_bits4))\n",
    "    print(\"\\nquant_scale for b1 is\\n{}\".format(frac_bits5))\n",
    "    print(\"\\nquant_scale for b2 is\\n{}\".format(frac_bits6))\n",
    "    print(\"\\nquant_scale for b3 is\\n{}\".format(frac_bits7))\n",
    "    print(\"\\nquant_scale for b4 is\\n{}\".format(frac_bits8))\n",
    "    spio.savemat(des_file,{\n",
    "                          'w1': quant_w1, 'w2': quant_w2, 'w3': quant_w3, 'w4': quant_w4,\n",
    "                          'b1': quant_b1, 'b2': quant_b2, 'b3': quant_b3, 'b4': quant_b4,\n",
    "                          's1':frac_bits1, 's2':frac_bits2, 's3':frac_bits3, 's4': frac_bits4,\n",
    "                          's5':frac_bits5, 's6':frac_bits6, 's7':frac_bits7, 's8': frac_bits8\n",
    "                         })\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# C_int8_w1 = \"int8 weight1[inband*bandnum][hiddenlayer1]={\"+\"{}\".format(\"test\")+\"}\"\n",
    "\n",
    "# C_int8_w2 = \"int8 weight2[hiddenlayer1][hiddenlayer2]=\\{{}\\}\"\n",
    "\n",
    "# C_int8_w3 = \"int8 weight3[hiddenlayer2][hiddenlayer3]=\\{{}\\}\"\n",
    "\n",
    "# C_int8_w4 = \"int8 weight4[hiddenlayer3][3]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_weight_string(oriWeight):\n",
    "    row_count = oriWeight.shape[0]\n",
    "    col_count = oriWeight.shape[1]\n",
    "    print(row_count,col_count)\n",
    "    matStr = \"\"\n",
    "    for i in range(row_count):\n",
    "        matStr=matStr+\"{\"\n",
    "        for j in range(col_count):\n",
    "            matStr = matStr + str(oriWeight[i][j]) + \",\"\n",
    "        matStr = matStr + \"},\\n\"\n",
    "    return matStr[0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_weight_flattened_w_string(oriWeight):\n",
    "    row_count = oriWeight.shape[0]\n",
    "    matStr = \"\"\n",
    "    for i in range(row_count):\n",
    "        matStr = matStr + str(oriWeight[i]) + \",\"\n",
    "    matStr = matStr + \"\\n\"\n",
    "    return matStr[0:-2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out_c_weights(srcWeightMatFile):\n",
    "    qw1,qw2,qw3,qw4,qb1,qb2,qb3,qb4=load_weights(srcWeightMatFile)\n",
    "    qw1 = qw1.flatten()\n",
    "    qw2 = qw2.flatten()\n",
    "    qw3 = qw3.flatten()\n",
    "    qw4 = qw4.flatten()\n",
    "    CurrentDateString = \"{}_{}\".format(str(date.today()).replace(\"-\", \"\"), \n",
    "                                       datetime.now().strftime(\"%H_%M_%S\"))\n",
    "    with open(\"../kws_c_weights/kws_c_weights_{}.h\".format(CurrentDateString),\"w\") as fw:\n",
    "        C_Head_Content = '''\n",
    "/*\n",
    " * nnCoeff.h\n",
    " *\n",
    " *  Created on: 2020/3/10\n",
    " *      Author: Rick\n",
    " */\n",
    "\n",
    "#ifndef NNCOEFF_H_\n",
    "#define NNCOEFF_H_\n",
    " '''\n",
    "        fw.writelines(C_Head_Content)\n",
    "        C_int8_w1 = \"int8 weight1[inband*bandnum][hiddenlayer1]={\"+\"{}\".format(ret_weight_flattened_w_string(qw1))+\"};\\n\"\n",
    "        C_int8_w2 = \"int8 weight2[hiddenlayer1][hiddenlayer2]={\"+\"{}\".format(ret_weight_flattened_w_string(qw2))+\"};\\n\"\n",
    "        C_int8_w3 = \"int8 weight3[hiddenlayer2][hiddenlayer3]={\"+\"{}\".format(ret_weight_flattened_w_string(qw3))+\"};\\n\"\n",
    "        C_int8_w4 = \"int8 weight4[hiddenlayer3][3]={\"+\"{}\".format(ret_weight_flattened_w_string(qw4))+\"};\\n\"\n",
    "        C_int8_b1 = \"int8 bias1[hiddenlayer1]={};\\n\".format(ret_weight_string(qb1))\n",
    "        C_int8_b2 = \"int8 bias2[hiddenlayer2]={};\\n\".format(ret_weight_string(qb2))\n",
    "        C_int8_b3 = \"int8 bias3[hiddenlayer3]={};\\n\".format(ret_weight_string(qb3))\n",
    "        C_int8_b4 = \"int8 bias4[3]={};\\n\".format(ret_weight_string(qb4))\n",
    "        fw.writelines(C_int8_w1)\n",
    "        fw.writelines(C_int8_w2)\n",
    "        fw.writelines(C_int8_w3)\n",
    "        fw.writelines(C_int8_w4)\n",
    "        fw.writelines(C_int8_b1)\n",
    "        fw.writelines(C_int8_b2)\n",
    "        fw.writelines(C_int8_b3)\n",
    "        fw.writelines(C_int8_b4)\n",
    "        fw.flush()\n",
    "        del C_Head_Content\n",
    "        del C_int8_w1\n",
    "        del C_int8_w2\n",
    "        del C_int8_w3\n",
    "        del C_int8_w4\n",
    "        del C_int8_b1\n",
    "        del C_int8_b2\n",
    "        del C_int8_b3\n",
    "        del C_int8_b4\n",
    "    del qw1\n",
    "    del qw2\n",
    "    del qw3\n",
    "    del qw4\n",
    "    del qb1\n",
    "    del qb2\n",
    "    del qb3\n",
    "    del qb4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 128\n",
      "1 128\n",
      "1 128\n",
      "1 3\n"
     ]
    }
   ],
   "source": [
    "write_out_c_weights(converted_training_mat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "quant_w2 is\n",
      "[[ 3 -3 -1 ... -1  0  0]\n",
      " [-2 -1  3 ... -1  1 -1]\n",
      " [ 1  1  0 ... -1 -2  0]\n",
      " ...\n",
      " [ 0  1  6 ...  1  1 -1]\n",
      " [ 3 -3  1 ...  1 -1 -2]\n",
      " [ 3  1  5 ...  1  2  1]]\n",
      "\n",
      "quant_scale for w1 is\n",
      "7\n",
      "\n",
      "quant_scale for w2 is\n",
      "8\n",
      "\n",
      "quant_scale for w3 is\n",
      "8\n",
      "\n",
      "quant_scale for w4 is\n",
      "9\n",
      "\n",
      "quant_scale for b1 is\n",
      "6\n",
      "\n",
      "quant_scale for b2 is\n",
      "6\n",
      "\n",
      "quant_scale for b3 is\n",
      "6\n",
      "\n",
      "quant_scale for b4 is\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "save_file =  \"../data/quantized_kws_weights/quant_kw_20200620.mat\"\n",
    "performConversion(originat_weight_mat,8,\"int8\",save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_mat(srcArray):\n",
    "    speech_mat_dict = {\"x_data\":srcArray}\n",
    "    spio.savemat(converted_mat_file,speech_mat_dict,oned_as='column')\n",
    "    \n",
    "def save_weight_mat(srcWeightFile, bits,typeStr):\n",
    "    weight1,weight2,weight3,bias1,bias2,bias3 = load_weights(srcWeightFile)\n",
    "    weight1 = performConvertion(weight1,bits,typeStr)\n",
    "    weight2 = performConvertion(weight2,bits,typeStr)\n",
    "    weight3 = performConvertion(weight3,bits,typeStr)\n",
    "    bias1 = performConvertion(bias1,bits,typeStr)\n",
    "    bias2 = performConvertion(bias2,bits,typeStr)\n",
    "    bias3 = performConvertion(bias3,bits,typeStr)\n",
    "    print(weight2)\n",
    "    spio.savemat(\"../../Weights/int{}_weights_for_original_128x32.mat\".format(bits),\n",
    "                     {'w1': weight1, 'w2': weight2, 'w3': weight3, 'b1': bias1, 'b2': bias2, 'b3': bias3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7   1  -3 ...  11  -1   1]\n",
      " [  4   1   2 ...  -5  -6   2]\n",
      " [ -1   0  -3 ...  -2 -10  15]\n",
      " ...\n",
      " [  5 -12   4 ...   4  -6  -2]\n",
      " [  0  -1   0 ...   0 -12  -9]\n",
      " [ -2   2   1 ...   4 -13  -3]]\n"
     ]
    }
   ],
   "source": [
    "save_weight_mat(converted_weight_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nctu_training_mat = \"../../speechData/nctu_origin_training_data/train_1106a_sharp_12.mat\"\n",
    "src_array = loaddata(nctu_training_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26684122 0.70283141 0.88426972 ... 0.71809787 0.16920831 0.16905722]\n",
      " [0.17060792 0.56428417 0.91814424 ... 0.75815144 0.05993171 0.0333237 ]\n",
      " [0.49442102 0.79770209 0.84977773 ... 0.84733115 0.0953902  0.        ]\n",
      " ...\n",
      " [0.7567909  0.99432799 0.70640176 ... 0.22294714 0.09880513 0.07683635]\n",
      " [0.76510084 0.99751292 0.69988347 ... 0.11805857 0.04398413 0.03533766]\n",
      " [0.75494277 0.99998792 0.6995279  ... 0.09852559 0.         0.01161164]]\n"
     ]
    }
   ],
   "source": [
    "print(src_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_ary = performConvertion(src_array,max_int32_value,\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 573037146 1509318960 1898954757 ... 1542103438  363372077  363047614]\n",
      " [ 366377713 1211791028 1971699742 ... 1628117816  128702374   71562108]\n",
      " [1061761056 1713052187 1824883783 ... 1819629791  204848902          0]\n",
      " ...\n",
      " [1625196090 2135303087 1516986224 ...  478775340  212182402  165004796]\n",
      " [1643041537 2142142687 1502988301 ...  253528839   94455201   75887043]\n",
      " [1621227245 2147457716 1502224725 ...  211582086          0   24935799]]\n"
     ]
    }
   ],
   "source": [
    "print(converted_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_mat(converted_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [15,10]\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import mediainfo\n",
    "import glob\n",
    "import scipy.io as spio\n",
    "import scipy.io.wavfile as sciwav\n",
    "import h5py\n",
    "import math\n",
    "from scipy.fftpack import dct\n",
    "import python_speech_features\n",
    "import os\n",
    "import sys\n",
    "scriptpath = \"../\"\n",
    "# Add the directory containing your module to the Python path (wants absolute paths)\n",
    "sys.path.append(os.path.abspath(scriptpath))\n",
    "from Libs.lcj_io import getDirsInFolder,getFilesInFloder\n",
    "import glob\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "# from sklearn.utils import shuffle\n",
    "from Libs.utils import get_recursive_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install surfboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywrod_train_root_dir = \"../Speech_DataSets/whole_keyword_clean_second_run_1429/\"\n",
    "timit_train_root_dir = \"../../Speech_DataSets/TIMIT/TRAIN/\"\n",
    "timit_train_dr1_root_dir = \"../../Speech_DataSets/TIMIT/TRAIN/DR1/\"\n",
    "timit_train_dr1_sub_1_dir = \"../../Speech_DataSets/TIMIT/TRAIN/DR1/MWAR0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORD_CLS = 1\n",
    "FILLER_CLS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hz2mel_nature(freq):\n",
    "    return 1127. * np.log(1. + freq / 700.)\n",
    "\n",
    "def mel2hz_nature(mel):\n",
    "    return 700. * (np.exp(mel / 1127.) - 1.)\n",
    "\n",
    "def hz2mel(hz):\n",
    "    return 2595 * np.log10(1+hz/700.)\n",
    "\n",
    "def mel2hz(mel):\n",
    "    return 700*(10**(mel/2595.0)-1)\n",
    "\n",
    "def round_half_up(number):\n",
    "    return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_filterbanks(nfilt=10,nfft=1024,samplerate=16000,lowfreq=0,highfreq=8000):\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    assert highfreq <= samplerate/2, \"highfreq is greater than samplerate/2\"\n",
    "    # compute points evenly spaced in mels\n",
    "    lowmel = hz2mel_nature(lowfreq)\n",
    "    highmel = hz2mel_nature(highfreq)\n",
    "    melpoints = np.linspace(lowmel,highmel,nfilt+2)\n",
    "    # our points are in Hz, but we use fft bins, so we have to convert\n",
    "    #  from Hz to fft bin number\n",
    "    mid_freqs = mel2hz_nature(melpoints)\n",
    "    \n",
    "    bins = np.floor((nfft+1)*mid_freqs/samplerate)\n",
    "    fbank = np.zeros([nfilt,nfft//2+1])\n",
    "    for j in range(0,nfilt):\n",
    "        for i in range(int(bins[j]), int(bins[j+1])):\n",
    "            fbank[j,i] = (i - bins[j]) / (bins[j+1]-bins[j])\n",
    "        for i in range(int(bins[j+1]), int(bins[j+2])):\n",
    "            fbank[j,i] = (bins[j+2]-i) / (bins[j+2]-bins[j+1])\n",
    "    return fbank\n",
    "\n",
    "def get_filterbank_from_midfreqs(midFreqs,samplerate, n_filt, n_fft):\n",
    "#     mid_freqs = midFreqs#[229.8,304.1,402.4,532.4,704.4,931.9,1233.1,1631.5,4000.,5500.]\n",
    "    target_mid_freqs = np.empty(n_filt+2,dtype=np.float)\n",
    "    idx = 0\n",
    "    for freq in midFreqs:\n",
    "        target_mid_freqs[idx] = freq\n",
    "        idx += 1\n",
    "#     print(target_mid_freqs)\n",
    "    bins = np.floor((n_fft+1)*target_mid_freqs/samplerate)\n",
    "#     print(len(bins))\n",
    "    fbank = np.zeros([n_filt,n_fft//2+1])\n",
    "    for j in range(0,n_filt):\n",
    "        for i in range(int(bins[j]), int(bins[j+1])):\n",
    "            fbank[j,i] = (i - bins[j]) / (bins[j+1]-bins[j])\n",
    "        for i in range(int(bins[j+1]), int(bins[j+2])):\n",
    "            fbank[j,i] = (bins[j+2]-i) / (bins[j+2]-bins[j+1])\n",
    "    return fbank\n",
    "\n",
    "def logfbank(signal,samplerate=16000,nfilt=10,nfft=1024,lowfreq=0,highfreq=8000):\n",
    "    feat,energy = fbank(signal,samplerate,lowfreq,highfreq)\n",
    "    return np.log(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magspec(frames, NFFT):\n",
    "    if np.shape(frames)[1] > NFFT:\n",
    "        logging.warn(\n",
    "            'frame length (%d) is greater than FFT size (%d), frame will be truncated. Increase NFFT to avoid.',\n",
    "            np.shape(frames)[1], NFFT)\n",
    "    complex_spec = np.fft.fft(frames, NFFT)\n",
    "#     print(complex_spec.shape)\n",
    "    return np.absolute(complex_spec)\n",
    "\n",
    "def powspec(frames, NFFT):\n",
    "    theFrames = magspec(frames,NFFT)\n",
    "    energy = np.sum(theFrames,1)\n",
    "    return np.square(theFrames), energy\n",
    "#     return 1.0 / NFFT * numpy.square(theFrames)\n",
    "\n",
    "def logpowspec(frames, NFFT=1024, norm=0):\n",
    "    ps = powspec(frames, NFFT);\n",
    "    ps[ps <= 1e-30] = 1e-30\n",
    "    lps = np.log(ps)\n",
    "    if norm:\n",
    "        return lps - np.max(lps)\n",
    "    else:\n",
    "        return lps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lifter(cepstra, L=22):\n",
    "    \"\"\"Apply a cepstral lifter the the matrix of cepstra. This has the effect of increasing the\n",
    "    magnitude of the high frequency DCT coeffs.\n",
    "    :param cepstra: the matrix of mel-cepstra, will be numframes * numcep in size.\n",
    "    :param L: the liftering coefficient to use. Default is 22. L <= 0 disables lifter.\n",
    "    \"\"\"\n",
    "    if L > 0:\n",
    "        nframes,ncoeff = np.shape(cepstra)\n",
    "        n = np.arange(ncoeff)\n",
    "        lift = 1 + (L/2.)*np.sin(np.pi*n/L)\n",
    "        return lift*cepstra\n",
    "    else:\n",
    "        # values of L <= 0, do nothing\n",
    "        return cepstra\n",
    "\n",
    "def delta(feat, N):\n",
    "    \"\"\"Compute delta features from a feature vector sequence.\n",
    "    :param feat: A numpy array of size (NUMFRAMES by number of features) containing features. Each row holds 1 feature vector.\n",
    "    :param N: For each frame, calculate delta features based on preceding and following N frames\n",
    "    :returns: A numpy array of size (NUMFRAMES by number of features) containing delta features. Each row del sig\n",
    "    del samp_freq\n",
    "    del sig_len\n",
    "    del frame_len\n",
    "    del over_lap\n",
    "    del step_len\n",
    "    del framed_sig\n",
    "    del frame_lps, _energy\n",
    "    del half_frame_lps\n",
    "    del wav_feat\n",
    "    del norm_wav_mfcc\n",
    "    print(flatten_mfcc.shape)\n",
    "    return flatten_mfccholds 1 delta feature vector.\n",
    "    \"\"\"\n",
    "    if N < 1:\n",
    "        raise ValueError('N must be an integer >= 1')\n",
    "    NUMFRAMES = len(feat)\n",
    "    denominator = 2 * sum([i**2 for i in range(1, N+1)])\n",
    "    delta_feat = np.empty_like(feat)\n",
    "    padded = np.pad(feat, ((N, N), (0, 0)), mode='edge')   # padded version of feat\n",
    "    for t in range(NUMFRAMES):\n",
    "        # [t : t+2*N+1] == [(N+t)-N : (N+t)+N+1]\n",
    "        delta_feat[t] = np.dot(np.arange(-N, N+1), padded[t : t+2*N+1]) / denominator  \n",
    "    return delta_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_signal(frames):\n",
    "    return frames/np.max(frames)\n",
    "\n",
    "def FormatWavSig_MS(norm_sig, sr):\n",
    "    strt_samp = 0\n",
    "    end_samp = len(norm_sig)\n",
    "    end_ms = len(norm_sig)/sr\n",
    "    xrange = np.linspace(0, end_ms, end_samp-strt_samp)\n",
    "    return strt_samp, end_samp, end_ms, xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_padlen(numframes, frame_step, frame_len):\n",
    "    return int((numframes - 1) * frame_step + frame_len)\n",
    "\n",
    "def calculate_frame_rate(sig_len, step_len):\n",
    "    return int( sig_len // step_len)\n",
    "\n",
    "def calculate_total_frames_of_signal(slen, frame_len, frame_step):\n",
    "    if slen <= frame_len:\n",
    "        numframes = 1\n",
    "        return numframes\n",
    "    else:\n",
    "        numframes = 1 + int(math.floor((1.0 * slen - frame_len) / frame_step))\n",
    "        return numframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framesig(sig, frame_len, frame_step):\n",
    "    slen = len(sig)\n",
    "#     frame_len = int(round_half_up(frame_len))\n",
    "#     frame_step = int(round_half_up(frame_step))\n",
    "    if slen <= frame_len:\n",
    "        numframes = 1\n",
    "    else:\n",
    "        numframes = 1 + int(math.ceil((1.0 * slen - frame_len) / frame_step))\n",
    "\n",
    "    padlen = int((numframes - 1) * frame_step + frame_len)\n",
    "    zeros = np.zeros((padlen - slen,))\n",
    "    padsignal = np.concatenate((sig, zeros))\n",
    "    indices = np.tile(np.arange(0, frame_len), (numframes, 1)) + np.tile(\n",
    "            np.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "    indices = np.array(indices, dtype=np.int32)\n",
    "    frames = padsignal[indices]\n",
    "    return  frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfsc(frames, nfft=1024):\n",
    "    ret_lps, theEnergy = powspec(frames,nfft)\n",
    "    return ret_lps, theEnergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "One may apply sinusoidal liftering1 to the MFCCs to de-emphasize higher MFCCs \n",
    "which has been claimed to improve speech recognition in noisy signals.\n",
    "\"\"\"\n",
    "def get_mfcc(spectrum,dct_type=2,num_ceps=13):\n",
    "    ret_mfcc = dct(spectrum, type=dct_type, axis=1, norm=\"ortho\")[:, 1 : (num_ceps + 1)]\n",
    "    return ret_mfcc\n",
    "\n",
    "def get_min_max_norm_mfcc(spectrum,dct_type=2,num_ceps=13):\n",
    "    _mfcc = dct(spectrum, type=dct_type, axis=1, norm=None)[:, 1 : (num_ceps + 1)]\n",
    "    min_ele = np.amin(_mfcc)\n",
    "    max_ele = np.amax(_mfcc)\n",
    "    norm_mfcc = (_mfcc-min_ele)/(max_ele-min_ele)\n",
    "    return norm_mfcc\n",
    "\n",
    "def get_max_norm_mfcc(spectrum,dct_type=2,num_ceps=13):\n",
    "    _mfcc = dct(spectrum, type=dct_type, axis=1, norm=None)[:, 1 : (num_ceps + 1)]\n",
    "    max_ele = np.amax(_mfcc)\n",
    "    norm_mfcc = _mfcc/max_ele\n",
    "    return norm_mfcc\n",
    "\n",
    "def get_lifted_mfcc(mfccs,num_lift=22):\n",
    "    (nframes, ncoeff) = ret_mfcc.shape\n",
    "    n = np.arange(ncoeff)\n",
    "    lift = 1 + (num_lift / 2) * np.sin(np.pi * n / num_lift)\n",
    "    lifted_mfcc = ret_mfcc * lift\n",
    "    return lifted_mfcc\n",
    "\n",
    "def get_mean_mfcc(mfccs):\n",
    "    mean_mfccs = mfccs - (np.mean(mfccs, axis=0) + 1e-8)\n",
    "    return mean_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_libosa_mfcc(frames, n_points, dct):\n",
    "    ret_mfcc = librosa.feature.mfcc(y=frames, sr=16000, dct_type=dct, n_mfcc=n_points)\n",
    "    return ret_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framingRawAudio(wavsig, seg_len, seg_step_len):\n",
    "    \"\"\"This function is used to frame the audio into 2D array, \n",
    "    and each row is one second long under 16K sample rate\n",
    "    \"\"\"\n",
    "    audio_frame_num = len(wavsig)\n",
    "    ret_array = framesig(wavsig, seg_len, seg_step_len)\n",
    "    return ret_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framing_Frames(frames, frame_length, hop_length):\n",
    "    overlap_len = frame_length - hop_length\n",
    "#     numFrames = calculate_total_frames_of_signal(framesLen, frame_length, hop_length)\n",
    "#     numCounter = 0\n",
    "    ff = framed_sig(frames, frame_length, hop_length)\n",
    "    return ff\n",
    "#     for audio_row in ff:\n",
    "        #perform mfcc calculation and add to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nfft(samplerate, winlen):\n",
    "    \"\"\"Calculates the FFT size as a power of two greater than or equal to\n",
    "    the number of samples in a single window length.\n",
    "    \n",
    "    Having an FFT less than the window length loses precision by dropping\n",
    "    many of the samples; a longer FFT than the window allows zero-padding\n",
    "    of the FFT buffer which is neutral in terms of frequency domain conversion.\n",
    "    :param samplerate: The sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: The length of the analysis window in seconds.\n",
    "    \"\"\"\n",
    "    window_length_samples = winlen * samplerate\n",
    "    nfft = 1\n",
    "    while nfft < window_length_samples:\n",
    "        nfft *= 2\n",
    "    return nfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_nfft(16000,0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train_data(save_path=None,index_array=None,mfcc_matrix=None,label_matrix=None,fn_matrix=None):\n",
    "    with h5py.File(save_path,\"w\") as f:\n",
    "        f.create_group('data1')\n",
    "        f.create_group('data2')\n",
    "        f.create_group('data3')\n",
    "        f.create_group('data4')\n",
    "        \n",
    "        f.create_dataset(\"x_data\",data=mfcc_matrix)\n",
    "        f.create_dataset(\"y_data\",data=label_matrix)\n",
    "        f.create_dataset(\"idx_data\", data= index_array)\n",
    "        f.create_dataset(\"file_list\", data=fn_matrix)\n",
    "        f.flush()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def save_train_data_in_npy(index_matrix=None,mfcc_matrix=None,label_matrix=None,fn_matrix=None):\n",
    "    np.save(\"../train_data/train_data.npy\",mfcc_matrix)\n",
    "    np.save(\"../train_data/train_lable.npy\",label_matrix)\n",
    "    np.save(\"../train_data/train_index.npy\",index_matrix)\n",
    "    np.save(\"../train_data/train_fn.npy\",fn_matrix)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wav_acoustic_features(wav_sig=None,sample_rate=None,fb=None,mfcc_type=1,sample_len=513,label=KEYWORD_CLS):\n",
    "#     samp_freq, sig = sciwav.read(wav_file)\n",
    "    sig = wav_sig\n",
    "    samp_freq = sample_rate\n",
    "    sig_len = len(sig)\n",
    "    frame_len = 400#int(samp_freq * 0.025) #25ms, 400\n",
    "    over_lap = 0#int(samp_freq * 0.0) #10ms, 160\n",
    "    step_len = 400#int(samp_freq * 0.025) #15ms, 240\n",
    "    framed_sig = framesig(sig,frame_len,step_len)\n",
    "    #the following is the logic of streaming logic\n",
    "    \n",
    "    frame_lps,_energy = get_mfsc(framed_sig) # get one second power-spectrum\n",
    "    half_frame_lps = np.split(frame_lps.T,[0,sample_len],axis=0)[1]\n",
    "    wav_feat = np.dot(half_frame_lps.T,fb.T)\n",
    "    wav_feat = np.log(wav_feat+np.finfo('float').eps)\n",
    "    norm_wav_mfcc = get_max_norm_mfcc(wav_feat)\n",
    "    flatten_mfcc = norm_wav_mfcc.flatten()#get_mfcc(wav_feat).flatten()\n",
    "    del sig\n",
    "    del samp_freq\n",
    "    del sig_len\n",
    "    del frame_len\n",
    "    del over_lap\n",
    "    del step_len\n",
    "    del framed_sig\n",
    "    del frame_lps, _energy\n",
    "    del half_frame_lps\n",
    "    del wav_feat\n",
    "    del norm_wav_mfcc\n",
    "    return flatten_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_streaming(wavfile=None):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_speech_path = '../../Speech_DataSets/TIMIT/TRAIN/DR1/MWAR0/SX55.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Train_Data(train_data_save_path,num_filt=40):\n",
    "    #     process_timit_config_list = []\n",
    "    fb_40 = get_default_filterbanks(nfilt=num_filt)\n",
    "    speech_files = getFilesInFloder(keywrod_train_root_dir)\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    fnlist = []\n",
    "    for speech_f in tqdm(speech_files):\n",
    "        if speech_f.endswith(\"wav\"):\n",
    "#             fn = f.split(\".\")[0]\n",
    "            full_path = keywrod_train_root_dir+speech_f\n",
    "            w_freq, w_sig = sciwav.read(full_path)\n",
    "            temp_mfcc = get_wav_acoustic_features(wav_sig=w_sig, sample_rate=w_freq,fb=fb_40)\n",
    "            data_list.append(temp_mfcc)\n",
    "            label_list.append([1,0])\n",
    "            fnlist.append(full_path.encode())\n",
    "            sleep(0.01)\n",
    "            \n",
    "    first_lvl_dirs = getDirsInFolder(timit_train_root_dir)\n",
    "    counter = 0\n",
    "    for lvl1d in tqdm(first_lvl_dirs):\n",
    "        second_lvl_dirs = getDirsInFolder(timit_train_root_dir+lvl1d)\n",
    "        for d in second_lvl_dirs:\n",
    "            current_folder = os.path.join(timit_train_root_dir,lvl1d,d)+\"/\"\n",
    "            files_list = getFilesInFloder(current_folder)\n",
    "            for f in files_list:\n",
    "                if f.endswith(\"wav\"):\n",
    "                    counter += 1\n",
    "                    full_path = current_folder+f\n",
    "                    w_freq, w_sig = sciwav.read(full_path)\n",
    "                    temp_mfcc = get_wav_acoustic_features(wav_sig=w_sig[0:16000], sample_rate=w_freq,fb=fb_40)\n",
    "                    data_list.append(temp_mfcc)\n",
    "                    label_list.append([0,1])\n",
    "                    fnlist.append(full_path.encode())\n",
    "                    sleep(0.01)\n",
    "    \n",
    "    data_array = np.array(data_list)\n",
    "    lbl_array = np.array(label_list).T\n",
    "    index_array = np.arange(len(data_list))\n",
    "    \n",
    "    file_array = np.array(fnlist)\n",
    "    print(\"total noise is: \", counter)\n",
    "    print(file_array.T.shape)\n",
    "    shuffled_idx_ary = shuffle(index_array)\n",
    "#     print(shuffled_idx_ary)\n",
    "    print(\"data shape:\",data_array.shape,\" lable shape:\",lbl_array.T.shape)\n",
    "    print(data_list[0])\n",
    "#     training_mat_dict = {\"x_data\":data_list}\n",
    "#     training_lbl_mat_dict = {\"y_data\":label_list}\n",
    "#     spio.savemat(\"../train_data/train_data_mat.mat\",training_mat_dict,oned_as='column')\n",
    "#     spio.savemat(\"../train_data/train_lable_mat.mat\",training_lbl_mat_dict,oned_as='row')\n",
    "#     save_train_data(train_data_save_path,shuffled_idx_ary,data_array,lbl_array.T,file_array.T)\n",
    "    save_train_data_in_npy(shuffled_idx_ary,data_array,lbl_array.T,file_array.T)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_data_save_path = \"../train_data/test_train_data.hdf5\"\n",
    "# # cent_bands = [0.0,195.0985245,251.8401972,312.1788118,376.342384,444.5733837,517.1296516,1550.447293,2554.078667,3461.030019,4620.759758,8000.0]\n",
    "# # _fb = get_filterbank_from_midfreqs(cent_bands,16000,40,1024)\n",
    "# _fb_40 = get_default_filterbanks(nfilt=40)\n",
    "# # _fb_26 = get_default_filterbanks(nfilt=26)\n",
    "# _freq, _sig = sciwav.read(test_speech_path)\n",
    "# loop_count = (len(_sig)//16000)\n",
    "# one_second_points = 16000\n",
    "# train_data_list = []\n",
    "# for i in range(loop_count):\n",
    "#     tmp_sig = _sig[i*one_second_points:(i+1)*one_second_points]\n",
    "#     tmp_mfcc = get_wav_acoustic_features(wav_sig=tmp_sig, sample_rate=_freq,fb=_fb_40)\n",
    "#     train_data_list.append(tmp_mfcc)\n",
    "#     del tmp_sig\n",
    "#     del tmp_mfcc\n",
    "    \n",
    "# data_array = np.array([train_data_list])\n",
    "# save_train_data(train_data_save_path,data_array[0])\n",
    "# print(data_array[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_read_h5(file_path):\n",
    "#     data_set = None\n",
    "#     with h5py.File(file_path,\"r\") as r:\n",
    "#         data_set = np.array(r[\"x_data\"])\n",
    "#     print(data_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_h5_file = \"../train_data/test_train_data.hdf5\"\n",
    "# test_read_h5(test_h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenData_Main(train_data_save_path,num_filt=40):\n",
    "#     process_timit_config_list = []\n",
    "    fb_40 = get_default_filterbanks(nfilt=num_filt)\n",
    "    speech_files = getFilesInFloder(keywrod_train_root_dir)\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    fnlist = []\n",
    "    for speech_f in tqdm(speech_files):\n",
    "        if speech_f.endswith(\"wav\"):\n",
    "#             fn = f.split(\".\")[0]\n",
    "            full_path = keywrod_train_root_dir+speech_f\n",
    "            w_freq, w_sig = sciwav.read(full_path)\n",
    "            temp_mfcc = get_wav_acoustic_features(wav_sig=w_sig, sample_rate=w_freq,fb=fb_40)\n",
    "            data_list.append(temp_mfcc)\n",
    "            label_list.append([1,0])\n",
    "            fnlist.append(full_path.encode())\n",
    "            sleep(0.01)\n",
    "            \n",
    "    first_lvl_dirs = getDirsInFolder(timit_train_root_dir)\n",
    "    counter = 0\n",
    "    for lvl1d in tqdm(first_lvl_dirs):\n",
    "        second_lvl_dirs = getDirsInFolder(timit_train_root_dir+lvl1d)\n",
    "        for d in second_lvl_dirs:\n",
    "            current_folder = os.path.join(timit_train_root_dir,lvl1d,d)+\"/\"\n",
    "            files_list = getFilesInFloder(current_folder)\n",
    "            for f in files_list:\n",
    "                if f.endswith(\"wav\"):\n",
    "                    counter += 1\n",
    "                    full_path = current_folder+f\n",
    "                    w_freq, w_sig = sciwav.read(full_path)\n",
    "                    temp_mfcc = get_wav_acoustic_features(wav_sig=w_sig[0:16000], sample_rate=w_freq,fb=fb_40)\n",
    "                    data_list.append(temp_mfcc)\n",
    "                    label_list.append([0,1])\n",
    "                    fnlist.append(full_path.encode())\n",
    "                    sleep(0.01)\n",
    "    \n",
    "    data_array = np.array(data_list)\n",
    "    lbl_array = np.array(label_list).T\n",
    "    index_array = np.arange(len(data_list))\n",
    "    \n",
    "    file_array = np.array(fnlist)\n",
    "    print(\"total noise is: \", counter)\n",
    "    print(file_array.T.shape)\n",
    "    shuffled_idx_ary = shuffle(index_array)\n",
    "#     print(shuffled_idx_ary)\n",
    "    print(\"data shape:\",data_array.shape,\" lable shape:\",lbl_array.T.shape)\n",
    "    print(data_list[0])\n",
    "#     training_mat_dict = {\"x_data\":data_list}\n",
    "#     training_lbl_mat_dict = {\"y_data\":label_list}\n",
    "#     spio.savemat(\"../train_data/train_data_mat.mat\",training_mat_dict,oned_as='column')\n",
    "#     spio.savemat(\"../train_data/train_lable_mat.mat\",training_lbl_mat_dict,oned_as='row')\n",
    "#     save_train_data(train_data_save_path,shuffled_idx_ary,data_array,lbl_array.T,file_array.T)\n",
    "    save_train_data_in_npy(shuffled_idx_ary,data_array,lbl_array.T,file_array.T)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 764/1504 [00:08<00:08, 89.66it/s]/home/user/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in true_divide\n",
      "100%|██████████| 1504/1504 [00:16<00:00, 89.77it/s]\n",
      "100%|██████████| 8/8 [00:51<00:00,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total noise is:  4620\n",
      "(6124,)\n",
      "data shape: (6124,)  lable shape: (6124, 2)\n",
      "[ 7.32890666e-01  1.84772549e-01  2.11117555e-01 -4.69129782e-01\n",
      " -1.83329295e-01 -5.76900931e-02 -2.85447163e-01 -9.87113826e-02\n",
      "  5.91450781e-02 -1.15874809e-01  1.17622075e-01  6.76127722e-02\n",
      " -5.12801990e-03  6.47753229e-01  1.46728434e-01  1.76967724e-01\n",
      " -2.50384840e-01 -2.03132516e-01 -4.86591900e-02 -2.66642415e-01\n",
      " -1.28154764e-01  1.95242102e-02 -7.38654964e-02  5.74522164e-02\n",
      "  7.15151044e-02 -1.26471324e-02  5.79844900e-01 -3.26022553e-02\n",
      "  9.71338529e-02 -2.30312938e-01 -2.62235148e-01 -6.05024611e-02\n",
      " -2.30293273e-01 -8.81531369e-02  3.87289425e-02 -4.47206290e-02\n",
      "  6.20161032e-02  8.40207453e-02  1.29488406e-02  6.44357554e-01\n",
      " -2.62953922e-01 -1.93010359e-02 -3.30094034e-01 -3.22518781e-01\n",
      " -4.40641364e-02 -1.76159150e-01 -9.71743978e-02 -4.76526280e-02\n",
      " -5.76124193e-02  7.02533517e-02 -4.76765407e-02 -8.63574670e-02\n",
      "  6.58477445e-01 -5.35569974e-01 -2.18176595e-01 -3.33423695e-01\n",
      " -7.75201672e-02  4.29755300e-03 -9.11632553e-02  1.30794591e-02\n",
      " -1.06484732e-01 -1.80890476e-01  9.86426278e-02 -1.51446396e-02\n",
      " -9.28202352e-02  5.55042787e-01 -5.61600965e-01 -3.02573578e-01\n",
      " -2.85772905e-01  5.85578541e-02 -7.13293766e-03  2.54243426e-02\n",
      "  2.24560434e-02 -2.50925318e-02 -2.17411667e-01  1.03500417e-01\n",
      "  7.45351456e-02 -3.47814147e-02  7.27074293e-01 -6.42099595e-01\n",
      " -3.93197209e-01 -1.80614101e-01  1.43915589e-02  2.48692789e-02\n",
      " -8.89518138e-02  8.41236402e-02 -2.57279437e-02 -1.88608615e-01\n",
      "  7.71289526e-02  1.12323760e-01 -6.99559675e-02  5.20715319e-01\n",
      " -5.43738199e-01 -4.78947869e-01 -1.88823443e-01 -5.93738123e-02\n",
      " -4.66769340e-02 -7.40637001e-02  1.79154775e-03 -6.09581403e-02\n",
      " -1.51567701e-01  5.82800019e-03  7.40416950e-02 -1.39872423e-02\n",
      "  4.48391111e-01 -4.20505248e-01 -4.26314239e-01 -2.54194710e-01\n",
      " -1.58958161e-01 -6.76882940e-02 -8.38878044e-02 -6.60537600e-02\n",
      " -6.09521766e-02 -1.49215910e-01 -6.12398358e-02  2.29599156e-02\n",
      " -4.16557648e-02  7.23223982e-01 -2.54270744e-01 -2.99008372e-01\n",
      " -2.39498107e-01 -6.01092327e-02 -1.02541196e-01 -1.20012016e-01\n",
      " -6.02905408e-02 -9.69558319e-02 -2.54481951e-01 -6.45244738e-02\n",
      "  3.29326679e-02 -6.18296587e-03  1.80882844e-01 -1.92175183e-01\n",
      " -3.01801105e-01 -1.59130331e-01 -1.40364372e-02 -2.66858728e-02\n",
      " -1.14913578e-02  1.79104073e-02  9.60603216e-02 -3.24922634e-01\n",
      "  9.71348116e-02 -7.62356308e-02 -5.72435327e-02 -6.06164273e-01\n",
      "  4.57027170e-03 -1.53078754e-01 -3.29315534e-01  1.73583872e-01\n",
      " -2.08313443e-01  5.13050550e-02 -9.15200965e-02 -5.34684885e-02\n",
      " -1.87955602e-01 -3.11681265e-02 -6.21239664e-02 -8.03015056e-02\n",
      " -8.93718297e-01  1.08995380e-01  6.20049022e-02 -2.80209590e-01\n",
      "  1.13619956e-01 -2.04898639e-01  3.98010034e-02 -9.33070723e-02\n",
      " -2.72504064e-02 -1.94124998e-01 -3.92600095e-02 -1.13349905e-01\n",
      " -4.37651322e-02 -8.62098474e-01  1.49873181e-01  5.33998415e-02\n",
      " -1.97086792e-01  1.51261327e-01 -1.50834497e-01  1.36562482e-01\n",
      " -2.86186990e-02  3.93795150e-03 -1.48944865e-01  7.29154646e-02\n",
      " -3.20233622e-02 -8.62659400e-04 -9.62268578e-01 -1.39950733e-02\n",
      "  9.76866733e-02 -3.05965726e-01  1.01892091e-01 -1.70200702e-01\n",
      "  6.93086963e-02 -7.13041925e-02  2.86770306e-02 -1.13719890e-01\n",
      "  7.57852842e-02  9.03283659e-03  4.69145037e-02  3.08988098e-01\n",
      "  3.04648374e-01  3.52386344e-01 -2.86140822e-01 -5.58427336e-02\n",
      " -1.60062777e-01 -1.74833090e-01 -1.87934117e-01  5.60331694e-02\n",
      " -9.07144160e-02 -7.06491870e-03 -2.44811960e-02 -3.30106638e-03\n",
      "  4.39798672e-01  6.70848861e-02  4.40880010e-01 -3.79119438e-01\n",
      " -4.96994706e-02 -1.16618172e-01 -1.89649290e-01 -2.40108416e-01\n",
      "  5.75103468e-02 -1.06183591e-01 -3.85001350e-02 -8.76289536e-03\n",
      "  7.52115094e-03  4.27894846e-01  6.42770093e-03  4.56769657e-01\n",
      " -4.59093075e-01 -1.29432177e-01 -1.61074456e-01 -1.94656402e-01\n",
      " -2.75260275e-01  9.57642613e-02 -8.03572011e-02 -8.49196150e-02\n",
      "  5.81186658e-04  2.70445016e-02  5.51010055e-01 -8.44767702e-02\n",
      "  2.98580761e-01 -4.47286783e-01 -2.27425626e-01 -2.63321776e-01\n",
      " -9.59252623e-02 -2.01909063e-01  1.33458511e-01 -7.68932976e-02\n",
      " -5.26736997e-03  1.33310334e-02 -4.28497303e-02  5.69163418e-01\n",
      " -1.95912269e-01 -5.15411139e-02 -3.19014809e-01 -1.49991659e-01\n",
      " -2.85610615e-01 -2.20705832e-01  5.31569491e-02  1.32241962e-01\n",
      " -1.19866976e-01 -1.36387350e-02  4.21133727e-02 -2.30467323e-02\n",
      "  6.35220140e-01 -1.48977971e-01 -1.89828613e-01 -2.04856851e-01\n",
      " -3.98560798e-02 -1.55849913e-01 -1.83169899e-01  3.30746905e-02\n",
      "  1.15729554e-01 -1.59785689e-02 -2.05594865e-02 -2.73204427e-02\n",
      "  1.68644163e-02  7.01550582e-01 -2.50963819e-02 -1.55488102e-01\n",
      " -2.78669853e-01  4.38002766e-03 -1.31561609e-01 -2.23775220e-01\n",
      "  5.05653501e-02  7.98001231e-02  2.71966864e-03  1.88334103e-02\n",
      " -1.00858070e-01 -3.67726515e-02  8.39182725e-01 -1.60437071e-02\n",
      " -2.28010746e-01 -5.31343610e-01  6.80037811e-02 -2.08962850e-01\n",
      " -2.01136913e-01 -1.31185337e-01  3.62281422e-02 -8.80781763e-02\n",
      "  1.42730817e-01 -4.15477538e-02 -1.77321281e-01  1.00000000e+00\n",
      "  1.26465420e-01 -1.44023233e-01 -3.98165471e-01  7.10142814e-02\n",
      " -1.99968507e-01 -1.00482743e-01 -9.41824174e-02  1.95014279e-02\n",
      " -5.32471485e-02  1.73133282e-01  1.83358894e-02 -7.03244907e-02\n",
      "  8.85296124e-01  7.93607668e-02 -2.12503139e-01 -2.41934833e-01\n",
      " -1.94816540e-02 -4.77038379e-02 -7.35838477e-02 -1.25494541e-01\n",
      " -3.73724751e-02 -2.99910349e-02  1.63625921e-01  5.94026472e-02\n",
      " -1.97002551e-02  7.65121955e-01  7.01354256e-03 -3.00665450e-01\n",
      " -2.74781912e-01  1.86933306e-02 -8.41883965e-02 -5.69831317e-02\n",
      " -1.30303466e-01 -6.07941480e-03  1.09527208e-02  1.65379270e-01\n",
      "  5.13602935e-02 -5.75489147e-02  5.90215095e-01 -2.61555917e-01\n",
      " -4.37470729e-01 -3.69249803e-01  2.19989961e-01 -1.14827938e-01\n",
      " -3.80815249e-02  4.13002251e-02  1.42153375e-01 -6.22658873e-02\n",
      " -4.91024674e-03 -1.08546924e-01 -6.32574858e-02  6.07712030e-01\n",
      " -4.63190514e-01 -3.65436395e-01 -2.16201971e-01  1.80777365e-01\n",
      " -7.50952181e-02 -2.29497337e-02  7.12776096e-02  2.11533846e-01\n",
      " -1.25920058e-01 -3.86335532e-02 -1.11524645e-02  5.75470861e-03\n",
      "  7.33107520e-01 -5.43458614e-01 -3.36422003e-01 -2.13157348e-01\n",
      "  1.37949686e-01 -9.49888170e-02 -3.78123715e-03  1.37372111e-02\n",
      "  2.09765300e-01 -2.04145279e-01 -8.02846370e-02  3.76112608e-02\n",
      "  6.91193407e-02  6.72839961e-01 -6.49095526e-01 -4.98884924e-01\n",
      " -2.94524989e-01  2.81646766e-02 -1.55972436e-01 -5.54151045e-02\n",
      "  4.98152424e-02  1.68550147e-01 -2.14162238e-01 -1.18670880e-01\n",
      "  1.35674308e-01  1.18071538e-01  8.65579987e-01 -6.15196650e-01\n",
      " -3.98119926e-01 -8.13701035e-02 -2.96870301e-02 -8.61401888e-02\n",
      " -8.02651696e-02  1.23099061e-01  9.66539123e-02 -1.57168764e-01\n",
      " -1.21126337e-01  1.10501136e-01  1.13083621e-01  8.55505812e-01\n",
      " -4.74388977e-01 -3.75381758e-01 -7.55264066e-02 -5.04949494e-02\n",
      " -1.16246990e-01 -3.49924026e-02  8.60079367e-02  6.73946137e-02\n",
      " -1.00295406e-01 -1.05016432e-01  6.58417505e-02  1.13347027e-01\n",
      "  8.66672854e-01 -5.03828005e-01 -4.88063745e-01 -1.41338398e-01\n",
      " -9.44154034e-02 -2.75689732e-01 -1.73235790e-01  1.77214783e-02\n",
      "  1.34129137e-02 -9.72892387e-02 -7.30456009e-02  3.37128266e-02\n",
      "  9.01227801e-02  8.79341273e-01 -3.65306090e-01 -3.36717445e-01\n",
      " -9.93040594e-02 -5.22270442e-02 -2.52982801e-01 -1.82318862e-01\n",
      " -5.70365646e-02 -4.19865970e-02 -1.88232230e-01 -8.89260460e-02\n",
      "  1.33107892e-02  1.06237653e-01  7.67035345e-01 -3.37261922e-01\n",
      " -3.21374487e-01 -1.17486363e-01 -2.42322839e-02 -1.30822844e-01\n",
      " -8.20234217e-02 -9.22682807e-02 -1.49584346e-01 -2.00504526e-01\n",
      " -3.69854389e-02  6.24129528e-02  3.72424171e-02  6.40583329e-01\n",
      " -4.61734776e-01 -2.87198744e-01  4.43327281e-02  5.73793969e-03\n",
      " -2.65777895e-02  2.19024020e-02 -3.95109666e-02  3.55364184e-02\n",
      " -2.14213295e-01 -5.56393937e-02  4.74277131e-02  7.63007633e-03\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_file = \"../train_data/train_data.hdf5\"\n",
    "GenData_Main(train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_wav_acoustic_features(wav_file):\n",
    "#     samp_freq, sig = sciwav.read(wav_file)\n",
    "#     sig_len = len(sig)\n",
    "#     frame_len = int(samp_freq * 0.025) #25ms, 400\n",
    "#     over_lap = int(samp_freq * 0.0) #10ms, 160\n",
    "#     step_len = int(samp_freq * 0.025) #15ms, 240\n",
    "#     print(frame_len, over_lap, step_len)\n",
    "#     frame_rate = calculate_frame_rate(samp_freq, step_len)\n",
    "\n",
    "\n",
    "    # sig = 1. * sig[1:16000]\n",
    "    # data = librosa.feature.melspectrogram(y=sig, sr=16000, n_mels=40, fmax=8000)\n",
    "    # data = librosa.power_to_db(data)\n",
    "    # mfccs = librosa.feature.mfcc(S=data,n_mfcc=39)\n",
    "    # plt.figure(figsize=(20, 4))\n",
    "    # librosa.display.specshow(data, x_axis='time')\n",
    "    # plt.colorbar()\n",
    "    # plt.title('MFCC')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # framing process\n",
    "    # total_frames = calculate_total_frames_of_signal(sig_len, frame_len, step_len)\n",
    "    # pad_len = calculate_padlen(total_frames, step_len, frame_len)\n",
    "    # print(sig_len, pad_len)\n",
    "    # framed_sig_1_sec = framesig(sig[0:16000],frame_len,step_len)\n",
    "    # print(framed_sig_1_sec[1,0:30])\n",
    "#     framed_sig = framesig(sig[0:16000],frame_len,step_len)\n",
    "#     print(framed_sig.shape)\n",
    "    # print(framed_sig[1,0:30])\n",
    "    # print(sig_row_num,16000/400)\n",
    "#     mfcc_list = []\n",
    "    # db_list = []\n",
    "#     stop_flag = 0\n",
    "#     for row in framed_sig:\n",
    "    #     if stop_flag > 2:\n",
    "    #         break\n",
    "#         data = librosa.feature.melspectrogram(y=row, sr=16000, n_mels=40, fmax=8000)\n",
    "#         data = librosa.power_to_db(data)\n",
    "        #, n_mfcc=10, dct_type=1\n",
    "#         mfccs = librosa.feature.mfcc(S=data, n_mfcc=20, dct_type=1)\n",
    "    #     if stop_flag < 2:\n",
    "    #         print(\"mfccs shape is\",mfccs)\n",
    "    #         plt.figure(figsize=(10, 4))\n",
    "    #         librosa.display.specshow(mfccs, x_axis='time')\n",
    "    #         plt.colorbar()\n",
    "    #         plt.title('MFCC')\n",
    "    #         plt.tight_layout()\n",
    "    #         plt.show()\n",
    "#         stop_flag += 1\n",
    "    #     db_list.append()\n",
    "    #     tmp_mfcc1 = get_mfcc(frames=row, n_points = , dct = 1)\n",
    "#         mfcc_list.append(mfccs[:,0])\n",
    "#         mfcc_list.append(mfccs[:,1])\n",
    "\n",
    "#     mfcc_ary = np.array(mfcc_list)\n",
    "#     reshape_colnum = mfcc_ary.shape[0] * mfcc_ary.shape[1]\n",
    "#     print(mfcc_ary.shape[0], mfcc_ary.shape[1])\n",
    "#     mfcc_ary = mfcc_ary.reshape(1,reshape_colnum)\n",
    "#     print(mfcc_ary)\n",
    "\n",
    "    # print(mfcc_ary)\n",
    "\n",
    "    #, n_mfcc=10, dct_type=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_sig = norm_signal(sig)\n",
    "# _strt_samp, _end_samp, _end_ms, _xrange = FormatWavSig_MS(norm_sig,samp_freq)\n",
    "# X = librosa.stft(norm_sig[_strt_samp:_end_samp], win_length=frame_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to arctic_a0005: 'will we ever forget it'\n",
    "# speech_path = '../../Speech_DataSets/TIMIT/TRAIN/DR1/MWAR0/SX55.wav'\n",
    "# sound = AudioSegment.from_wav(speech_path)  # Read audio file\n",
    "# sound_samples = sound.get_array_of_samples()  # Extract signal samples\n",
    "# samp_freq = sound.frame_rate  # Sampling frequency\n",
    "\n",
    "# # Normilze to max amplitude of 1\n",
    "# speech_samples_norm = np.array(sound_samples)/np.max(np.array(sound_samples))\n",
    "\n",
    "# strt_samp = 0\n",
    "# end_samp = len(speech_samples_norm)\n",
    "# end_ms = len(speech_samples_norm)/samp_freq\n",
    "\n",
    "# xrange = np.linspace(0, end_ms, end_samp-strt_samp)\n",
    "\n",
    "# # Plot speech and the corresponding spectrogram\n",
    "# fg1 = plt.figure(figsize=(18, 8))\n",
    "# plt.plot(xrange, speech_samples_norm)\n",
    "# plt.xlabel('Time in seconds')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.axis('tight')\n",
    "\n",
    "# # fg1.savefig('speech.jpg')\n",
    "\n",
    "# winlen = int(samp_freq*.025)  # Window size of 30 ms\n",
    "# X = librosa.stft(\n",
    "#     np.array(speech_samples_norm[strt_samp:end_samp]), win_length=winlen)\n",
    "# Xdb = librosa.amplitude_to_db(abs(X))\n",
    "# fg2 = plt.figure(figsize=(18, 8))\n",
    "# librosa.display.specshow(Xdb, sr=samp_freq, x_axis='time',\n",
    "#                          y_axis='hz', hop_length=winlen/4)\n",
    "\n",
    "# fg2.savefig('specgram.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo('float').eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
